
UDF Container Directory Layout
------------------------------


#. A native C++ and Python UDF container source base is shown as follows:
   ..

      **Note:** Based on a use case, the native C++ and Python container source base can look different.


.. code-block:: bash

   NativeSafetyGearAnalytics
   ├── config.json
   ├── docker-compose.yml
   ├── Dockerfile
   └── safety_gear_demo
       ├── CMakeLists.txt
       ├── ref
       │   ├── frozen_inference_graph.bin
       │   ├── frozen_inference_graph_fp16.bin
       │   ├── frozen_inference_graph_fp16.xml
       │   └── frozen_inference_graph.xml
       ├── safety_gear_demo.cpp
       └── safety_gear_demo.h

The Python containers typically look as follows:

.. code-block:: bash

   PyMultiClassificationIngestion
   ├── config.json
   ├── docker-compose.yml
   ├── Dockerfile
   └── sample_classification
       ├── __init__.py
       ├── multi_class_classifier.py
       └── ref
           ├── squeezenet1.1_FP16.bin
           ├── squeezenet1.1_FP16.xml
           ├── squeezenet1.1_FP32.bin
           ├── squeezenet1.1_FP32.xml
           └── squeezenet1.1.labels

The top-level directories **"NativeSafetyGearAnalytics"** and **"PyMultiClassificationIngestion"** hosts the container's build ingredients. The Algo or pre-processing logics are placed under the examples **"safety_gear_demo"** and **sample_classification** to showcase a grouping of logically related entities. This is not a mandatory directory layout.


* ## *config.json*

This file defines UDF specific configuration and other generic configs such as queue-depth, number-of-worker-thread etc. These generic configs can be added to overwrite any default of setting of VI and VA container.

For more information about schema of defining the configs and its permissible values, refer to the `UDF-README <https://github.com/open-edge-insights/video-common/blob/master/udfs/README.md>`_ file.

For ingestor related configs, refer to the `VideoIngestion-README <https://github.com/open-edge-insights/video-ingestion/blob/master/README.md>`_.

An example snippet of the configuration is as follows:

.. code-block:: bash

       {
           "encoding": {
               "level": 95,
               "type": "jpeg"
           },
           "max_jobs": 20,
           "max_workers": 4,
           "queue_size": 10,
           "udfs": [
               {
                   "name": "safety_gear_demo",
                   "type": "native",
                   "device": "CPU",
                   "model_xml": "./safety_gear_demo/ref/frozen_inference_graph.xml",
                   "model_bin": "./safety_gear_demo/ref/frozen_inference_graph.bin"
               }
           ]
       }


* ## *Dockerfile*

This file defines the container build process. All the build time and runtime artifacts should be copied to the container. For the native (C++) UDF, describe the destination path to copy the code to the native UDF and compilation instruction of the same. For Python, copy the UDF defining artifacts to a proper destination location. Some code comments are provided for describing the important key values.

An example of **Dockerfile** for C++ based UDF is as follows:

.. code-block:: dockerfile

   ARG EII_VERSION                                          <<<<This is to use latest version of VI & VA automatically instead of hardcoding a version
   ARG DOCKER_REGISTRY
   ARG ARTIFACTS="/artifacts"
   FROM ia_video_common:$EII_VERSION as video_common
   FROM ia_openvino_base:$EII_VERSION as openvino_base
   FROM ${DOCKER_REGISTRY}openedgeinsights/ia_video_analytics:$EII_VERSION as video_analytics
   FROM ia_eiibase:$EII_VERSION as builder
   LABEL description="C++ based Safety Gear UDF Image"
   WORKDIR /app
   ARG ARTIFACTS
   RUN mkdir $ARTIFACTS \
             $ARTIFACTS/safety_gear_demo \
             $ARTIFACTS/lib
   ARG CMAKE_INSTALL_PREFIX
   COPY --from=video_common ${CMAKE_INSTALL_PREFIX}/include ${CMAKE_INSTALL_PREFIX}/include
   COPY --from=video_common ${CMAKE_INSTALL_PREFIX}/lib ${CMAKE_INSTALL_PREFIX}/lib
   COPY --from=openvino_base /opt/intel /opt/intel

   # Copy more than one UDFs here
   # Both C++ & Python are allowed in a container.
   COPY ./safety_gear_demo/ ./safety_gear_demo
   RUN cp -r ./safety_gear_demo $ARTIFACTS/safety_gear_demo

   # Build native UDF samples
   RUN /bin/bash -c "source /opt/intel/openvino/bin/setupvars.sh && \
       cd ./safety_gear_demo && \
       rm -rf build && \
       mkdir build && \
       cd build && \
       cmake -DCMAKE_INSTALL_INCLUDEDIR=${CMAKE_INSTALL_PREFIX}/include -DCMAKE_INSTALL_PREFIX=$CMAKE_INSTALL_PREFIX -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE} .. && \
       make"

   RUN cp ./safety_gear_demo/build/libsafety_gear_demo.so $ARTIFACTS/lib

   FROM video_analytics as runtime   <<<<<This container is based VA container
   HEALTHCHECK NONE
   WORKDIR /app
   ARG ARTIFACTS
   ARG CMAKE_INSTALL_PREFIX
   COPY --from=builder $ARTIFACTS/lib ${CMAKE_INSTALL_PREFIX}/lib
   COPY --from=builder $ARTIFACTS/safety_gear_demo .

An Example of Python based UDF's **Dockerfile** will look as follows:

.. code-block:: dockerfile

   ARG EII_VERSION
   ARG DOCKER_REGISTRY
   FROM ${DOCKER_REGISTRY}openedgeinsights/ia_video_ingestion:$EII_VERSION
   LABEL description="Multi-class clasifcation UDF Image"
   WORKDIR /app

   # Added /app to python path as copying the UDF code block under /app
   # else user can add the path to which it copies its udf code.
   ENV PYTHONPATH ${PYTHONPATH}:/app
   # User can mention about all UDF directories here, both py and C++.
   COPY ./sample_classification ./sample_classification  <<<<< ./sample_classification is the destination here for UdfLoader to pick it at runtime. Additionally we have set the python path forUdfLoader to identify the algo artifacts properly.


* 
  ## *docker-compose.yml*

  The ``docker-compose.yml`` makes the custom UDF container to be managed by the OEI infrastructure. The content for this file also defines how the UDF container will communicate with other containers via the messagebus. Some of the important key-value pairs of this ``docker-compose.yml`` file is described in the following code snippet. If required, you can change the value of certain keys. The following keys should be changed for a different UDF container. Import key-value combinations are described in the code comments with prescript of "<<<<<".

  .. code-block:: yml

       services:
         python_multi_classification:      <<<<< Define the name of the container
           build:
             context: $PWD/../CustomUdfs/PyMultiClassificationIngestion                 <<<<< This path should be the relative path of container artifact
             dockerfile: $PWD/../CustomUdfs/PyMultiClassificationIngestion/Dockerfile   <<<<< Path to Dockerfile of the container
       -----snip-----
           image: ${DOCKER_REGISTRY}python_multi_classification:${EII_VERSION} <<<<< Image Name
           container_name: python_multi_classification                         <<<<< container Name
           hostname: python_multi_classification                               <<<<< Docker Network Namespace defined container name
       -----snip----
           environment:
             AppName: "PyMultiClassificationIngestion"                                  <<<<< Application name which will be used by configuration server & for security purpose.
       ----snip------
             PubTopics: "py_analytic_result_strm"                              <<<<< Publisher topic of this container And sub topic can be added based on need
             py_analytic_result_strm_cfg: "zmq_ipc,${SOCKET_DIR}/"
             Server: "zmq_tcp,127.0.0.1:66018"
       -----snip------
           privileged: true
           devices:
             - "/dev/:/dev/"
           volumes:                                                             <<<<< In the PROD mode the "volumes" section need to be defined as described.
             - ./Certificates/PyMultiClassificationIngestion:/run/secrets/PyMultiClassificationIngestion:ro
             - ./Certificates/rootca/cacert.pem:/run/secrets/rootca/cacert.pem:ro

* 
  ## *UDF core-logic Directory*

This directory need to have the Algo/pre-processing implementation which defines the necessary callbacks, IR files, and other configurational files, as per need. You can place them directly without having another directory level too. In that case, the **Dockerfile** and **docker-compose.yml** should update the path accordingly.
